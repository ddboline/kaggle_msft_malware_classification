#!/usr/bin/python

import os
import gzip
import csv
import glob
import multiprocessing
from collections import deque, defaultdict

import pandas as pd
import numpy as np

def read_feature_dict(prefix):
    ngram_count = {}
    with gzip.open('%s.ngram.gz' % prefix, 'rb') as ngramfile:
        for line in ngramfile:
            if line.find('ngram') == 0:
                continue
            w, c = line.split(',')
            ngram_count[w] = int(c)
    return prefix, ngram_count

if __name__ == '__main__':
    train_labels = pd.read_csv('trainLabels.csv')

    classes = set(train_labels['Class'].unique())
    train_dict = dict(zip(train_labels['Id'].tolist(), train_labels['Class'].tolist()))

    dir_to_process = os.sys.argv[1]
    ncpu = len(filter(lambda x: x.find('processor')==0, 
                      open('/proc/cpuinfo')
                      .read().split('\n')))
    print 'ncpu', ncpu
    prefixes = map(lambda x: x.replace('.ngram.gz',''), glob.glob('%s/*.ngram.gz' % dir_to_process))
    
    total_ngram_count = defaultdict(int)
    per_class_ngram_count = {cl: defaultdict(int) for cl in classes}
    
    idx = 0
    totn = len(prefixes)
    for prefix, nd in map(read_feature_dict, prefixes):
        pkey = os.path.basename(prefix)
        print idx, totn, pkey
        class_ = train_dict[pkey]
        for w, c in nd.items():
            total_ngram_count[w] += c
            per_class_ngram_count[class_][w] += c
        idx += 1

    for prefix, ngram_count in [('total', total_ngram_count)]+[('class%d' % idx, per_class_ngram_count[idx]) for idx in classes]:
        with gzip.open('%s.csv.gz' % prefix, 'wb') as ngramfile:
            ngramfile.write('ngram,count\n')
            for w, c in sorted(ngram_count.items(), key=lambda x: x[1]):
                ngramfile.write('%s,%s\n' % (w, c))
