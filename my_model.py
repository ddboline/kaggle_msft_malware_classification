#!/usr/bin/python

import os
import gzip

import cPickle as pickle

from load_data import load_data
#from load_data_bagofwords import load_data

from sklearn.linear_model import SGDClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.ensemble import RandomForestClassifier

from sklearn.cross_validation import train_test_split
from sklearn.grid_search import RandomizedSearchCV, GridSearchCV
from sklearn.metrics import log_loss

import numpy as np
import pandas as pd

NCLASSES = 9

def score_model(model, xtrain, ytrain):
    randint = reduce(lambda x,y: x|y, [ord(x)<<(n*8) for (n,x) in
                                       enumerate(os.urandom(4))])
    xTrain, xTest, yTrain, yTest = train_test_split(xtrain, ytrain,
                                                    test_size=0.4,
                                                    random_state=randint)
    model.fit(xTrain, yTrain)
    print model
    print model.score(xTest, yTest)
    return

def scorer(estimator, X, y):
    yprob = estimator.predict_proba(X)
    return 1.0 / log_loss(y, yprob)

def train_model_parallel(model, xtrain, ytrain, index):
    randint = reduce(lambda x,y: x|y, [ord(x)<<(n*8) for (n,x) in enumerate(os.urandom(4))])
    xTrain, xTest, yTrain, yTest = \
      train_test_split(xtrain, ytrain[:,index], test_size=0.4,
                                        random_state=randint)
    n_est = [10, 100, 200]
    m_dep = [5, 10, 40]

    model = GridSearchCV(estimator=model,
                                param_grid=dict(n_estimators=n_est, max_depth=m_dep),
                                scoring=scorer,
                                n_jobs=-1, verbose=1)
    model.fit(xTrain, yTrain)
    print model

    ytest_prob = model.predict_proba(xTest)
    print 'logloss', log_loss(yTest, ytest_prob)
    with gzip.open('model_%d.pkl.gz' % index, 'wb') as mfile:
        pickle.dump(model, mfile, protocol=2)
    return

def test_model_parallel(xtrain, ytrain):
    randint = reduce(lambda x,y: x|y, [ord(x)<<(n*8) for (n,x) in enumerate(os.urandom(4))])
    xTrain, xTest, yTrain, yTest = \
      train_test_split(xtrain, ytrain, test_size=0.4,
                                        random_state=randint)
    ytest_prob = np.zeros((yTest.shape[0], yTest.shape[1], 2))
    sum_log_loss = 0
    for n in range(NCLASSES):
        with gzip.open('model_%d.pkl.gz' % n, 'rb') as mfile:
            model = pickle.load(mfile)
            print 'grid scores', model.grid_scores_
            print 'best score', model.best_score_
            print 'best params', model.best_params_
            pyt = model.predict_proba(xTest)
            ytest_prob[:,n,:] = pyt
            sum_log_loss += log_loss(yTest[:,n], pyt)
    print sum_log_loss

def prepare_submission_parallel(xtrain, ytrain, xtest, ytest):
    for n in range(NCLASSES):
        with gzip.open('model_%d.pkl.gz' % n, 'rb') as mfile:
            model = pickle.load(mfile)
            ytest_prob = model.predict_proba(xtest)
            label = 'Prediction%d' % (n+1)
            ytest[label] = ytest_prob[:,1]
    ytest.to_csv('submission.csv', index=False, float_format='%.6f')

if __name__ == '__main__':
    xtrain, ytrain, xtest, ytest = load_data()

    #model = RandomForestClassifier(n_estimators=400, n_jobs=-1)
    #model = SGDClassifier(loss='log', n_jobs=-1, penalty='l1', verbose=1, n_iter=200)
    model = GradientBoostingClassifier(loss='deviance', verbose=1)

    #score_model(model, xtrain, ytrain)
    #prepare_submission(model, xtrain, ytrain, xtest, ytest)

    index = -1
    for arg in os.sys.argv:
        try:
            index = int(arg)
            break
        except ValueError:
            continue
    if index == -1:
        score_model(model, xtrain, ytrain)
    elif index >= 0 and index < 9:
        train_model_parallel(model, xtrain, ytrain, index)
    elif index == 9:
        test_model_parallel(xtrain, ytrain)
    elif index == 10:
        prepare_submission_parallel(xtrain, ytrain, xtest, ytest)

