#!/usr/bin/python

import os
import csv
import gzip
import glob
import multiprocessing
from collections import defaultdict

import pandas as pd
import numpy as np

def read_feature_dict(ngram_list, inq, outq):
    while True:
        if inq.empty():
            continue
        prefix = inq.get()
        if prefix == 'STOP':
            outq.put('FINISHED')
            break
        else:
            pkey = os.path.basename(prefix)
            outq.put(prefix)
            with gzip.open('%s.ngram.gz' % prefix, 'rb') as ngramfile:
                feature_dict = {w: 0 for w in ngram_list}
                for line in ngramfile:
                    if line.find('ngram') == 0:
                        continue
                    w, c = line.split(',')
                    if w in feature_dict:
                        feature_dict[w] += int(c)
                outq.put((os.path.basename(prefix), feature_dict))
    return


def read_ngrams(nfeatures=100):
    train_df = pd.read_csv('trainLabels.csv')
    submit_df = pd.read_csv('sampleSubmission.csv')
    total_df = pd.read_csv('total.csv.gz', compression='gzip')

    test_df = pd.DataFrame()
    test_df['Id'] = submit_df['Id']
    
    train_list = train_df['Id'].tolist()
    test_list = test_df['Id'].tolist()
    
    ngram_list = sorted(total_df['ngram'].iloc[-nfeatures:].tolist())

    for n in range(nfeatures):
        train_df['ngram%d' % n] = np.zeros(train_df.shape[0], dtype=np.float64)
        test_df['ngram%d' % n] = np.zeros(test_df.shape[0], dtype=np.float64)

    print train_df.columns
    print test_df.columns
    print total_df.columns

    train_dir = os.sys.argv[1]
    test_dir = os.sys.argv[2]
    ncpu = len(filter(lambda x: x.find('processor')==0, 
                      open('/proc/cpuinfo')
                      .read().split('\n')))
    print 'ncpu', ncpu

    input_queue = multiprocessing.Queue()
    output_queue = multiprocessing.Queue()
    
    workers = [multiprocessing.Process(target=read_feature_dict, args=(ngram_list, input_queue, output_queue,)) for _ in range(ncpu)]
    
    for w in workers:
        w.start()

    
    prefixes = map(lambda x: x.replace('.ngram.gz',''),
                   glob.glob('%s/*.ngram.gz' % train_dir)
                   + glob.glob('%s/*.ngram.gz' % test_dir))

    for prefix in prefixes:
        input_queue.put(prefix)
    
    for w in workers:
        input_queue.put('STOP')

    nfinished = 0
    while True:
        if nfinished == ncpu:
            break
        if output_queue.empty():
            continue
        _tmp = output_queue.get()
        if _tmp == 'FINISHED':
            nfinished += 1
        elif type(_tmp) == str:
            print _tmp
        else:
            pre, ndict = _tmp
            if pre in train_list:
                ngram_vec = np.zeros((1,nfeatures))
                for idx, ngram in enumerate(ngram_list):
                    ngram_vec[idx] = ndict[ngram]
                ngram_vec = np.divide(ngram_vec, ngram_vec.sum())
                train_df.loc[train_df['Id'] == pre,:] = ngram_vec[0,:]
            elif pre in test_list:
                ngram_vec = np.zeros(nfeatures)
                for idx, ngram in enumerate(ngram_list):
                    ngram_vec[idx] = ndict[ngram]
                ngram_vec = np.divide(ngram, ngram.sum())
                test_df.loc[test_df['Id'] == pre] = ngram_vec

    with gzip.open('train_df.csv.gz', 'wb') as outfile:
        train_df.to_csv(outfile, index=False)
    with gzip.open('test_df.csv.gz', 'wb') as outfile:
        test_df.to_csv(outfile, index=False)
    #return xtrain, ytrain, xtest, ytest

def load_data():
    train_df = pd.read_csv('train_df.csv.gz', compression='gzip')
    test_df = pd.read_csv('test_df.csv.gz', compression='gzip')
    submit_df = pd.read_csv('sampleSubmission.csv')
    
    xtrain = train_df.drop(labels=['Id', 'Class'], axis=1).values
    ytrain = train_df['Class'].values
    xtest = test_df.drop(labels=['Id'], axis=1).values
    ytest = submit_df
    
    return xtrain, ytrain, xtest, ytest
    
if __name__ == '__main__':
    read_ngrams(nfeatures=100)
    #xtrain, ytrain, xtest, ytest = load_data()

    #print xtrain.shape, ytrain.shape, xtest.shape, ytest.shape
