#!/usr/bin/python

import os
import gzip
import csv
import glob
import multiprocessing
from collections import deque, defaultdict

def feature_extraction(prefix):
    ngram_count = defaultdict(int)
    most_recent_bytes = deque(maxlen=2)
    with gzip.open('%s.bytes.gz' % prefix, 'rb') as asmfile:
        for line in asmfile:
            for ent in line.split()[1:]:
                most_recent_bytes.append(ent)
                if len(most_recent_bytes) != 2:
                    continue
                ngram_count[''.join(most_recent_bytes)] += 1
    with gzip.open('%s.ngram.gz' % prefix, 'wb') as ngramfile:
        ngramfile.write('ngram,count\n')
        for w, c in sorted(ngram_count.items(), key=lambda x: x[1]):
            ngramfile.write('%s,%s\n' % (w, c))
    return True

if __name__ == '__main__':
    dir_to_process = os.sys.argv[1]
    ncpu = len(filter(lambda x: x.find('processor')==0, 
                      open('/proc/cpuinfo')
                      .read().split('\n')))
    #feature_extraction(os.sys.argv[1])
    prefixes = map(lambda x: x.replace('.bytes.gz',''), glob.glob('%s/*.bytes.gz' % dir_to_process))
    pool = multiprocessing.Pool(ncpu)
    for r in pool.imap_unordered(feature_extraction, prefixes):
        pass
